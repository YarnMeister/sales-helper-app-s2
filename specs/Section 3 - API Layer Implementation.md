Section 3: API Layer Implementation
3.1 Core Request Management API
Goal: Implement CRUD operations for requests with proper validation and PRD-specific filtering
Cursor Prompt:
Create the core requests API with full CRUD operations, validation, error handling, and PRD-specific filtering patterns.

Create `/app/api/requests/route.ts`:

import { NextRequest } from 'next/server';
import { getDb, generateRequestId, withDbErrorHandling } from '@/lib/db';
import { RequestUpsert } from '@/lib/schema';
import { errorToResponse, ValidationError, NotFoundError } from '@/lib/errors';
import { log } from '@/lib/log';

export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const status = searchParams.get('status');
    const mineGroup = searchParams.get('mineGroup');
    const mineName = searchParams.get('mineName');
    const personId = searchParams.get('personId');
    const salesperson = searchParams.get('salesperson'); // PRD: Luyanda, James, Stefan
    const showAll = searchParams.get('showAll') === 'true'; // PRD: Toggle for showing all requests
    const limit = parseInt(searchParams.get('limit') || '50');
    
    const db = getDb();
    let query = db
      .from('requests')
      .select('*')
      .order('created_at', { ascending: false })
      .limit(limit);
    
    // PRD requirement: Filter by salesperson unless showAll is true
    if (!showAll && salesperson && salesperson !== 'all') {
      query = query.eq('salesperson_first_name', salesperson);
    }
    
    if (status) {
      query = query.eq('status', status);
    }
    if (mineGroup) {
      query = query.eq('contact_mine_group', mineGroup);
    }
    if (mineName) {
      query = query.eq('contact_mine_name', mineName);
    }
    if (personId) {
      query = query.eq('contact_person_id_int', parseInt(personId));
    }
    
    const { data, error } = await query;
    
    if (error) {
      log('Error fetching requests', { error, filters: { status, mineGroup, mineName, personId, salesperson, showAll } });
      throw error;
    }
    
    // PRD requirement: Control "New Request" button visibility
    const showNewButton = !showAll;
    
    return Response.json({ 
      ok: true, 
      data,
      showNewButton,
      filters: { salesperson, showAll }
    });
    
  } catch (e) {
    return errorToResponse(e);
  }
}

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const parsed = RequestUpsert.parse(body);
    
    const db = getDb();
    
    // PRD: Support inline updates for contact, line_items, comment
    const updates = {
      id: parsed.id,
      request_id: parsed.request_id,
      ...(parsed.contact && { contact: parsed.contact }),
      ...(parsed.line_items && { line_items: parsed.line_items }),
      ...(parsed.comment !== undefined && { comment: parsed.comment }),
      updated_at: new Date().toISOString()
    };
    
    // Generate request_id for new requests (auto-handled by database trigger)
    if (!parsed.id) {
      updates.salesperson_first_name = parsed.salespersonFirstName;
      updates.mine_group = parsed.mineGroup;
      updates.mine_name = parsed.mineName;
      updates.status = 'draft';
      // request_id will be auto-generated by database trigger
    }
    
    const { data, error } = await db
      .from('requests')
      .upsert(updates)
      .select()
      .single();
    
    if (error) {
      log('Error saving request', { error, data: parsed });
      throw error;
    }
    
    log('Request saved successfully', { request_id: data.request_id, inline_update: !!parsed.id });
    return Response.json({ ok: true, data });
    
  } catch (e) {
    if (e instanceof z.ZodError) {
      return errorToResponse(new ValidationError('Invalid request data', e.errors));
    }
    return errorToResponse(e);
  }
}

export async function DELETE(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const id = searchParams.get('id');
    
    if (!id) {
      throw new ValidationError('Missing request ID');
    }
    
    const db = getDb();
    const { error } = await db
      .from('requests')
      .delete()
      .eq('id', id);
    
    if (error) {
      log('Error deleting request', { error, id });
      throw error;
    }
    
    log('Request deleted successfully', { id });
    return Response.json({ ok: true });
    
  } catch (e) {
    return errorToResponse(e);
  }
}

Create unit tests in `/tests/unit/requests-api.test.ts`:

import { describe, it, expect } from 'vitest';
import { RequestUpsert } from '../../lib/schema';

describe('Requests API', () => {
  it('should validate request data correctly', () => {
    const validData = {
      salespersonFirstName: 'John',
      contact: {
        personId: 123,
        name: 'Test Contact'
      },
      line_items: [{
        pipedriveProductId: 456,
        name: 'Test Product',
        quantity: 2
      }]
    };
    
    const result = RequestUpsert.safeParse(validData);
    expect(result.success).toBe(true);
  });
  
  it('should reject invalid request data', () => {
    const invalidData = {
      contact: {
        personId: 'not-a-number',
        name: ''
      }
    };
    
    const result = RequestUpsert.safeParse(invalidData);
    expect(result.success).toBe(false);
  });

  it('should support PRD inline update pattern', () => {
    const inlineUpdate = {
      id: 'existing-uuid',
      contact: { personId: 123, name: 'Updated Contact' },
      comment: 'Updated comment'
    };
    
    const result = RequestUpsert.safeParse(inlineUpdate);
    expect(result.success).toBe(true);
  });
});
Manual Validation Steps:

 Test GET /api/requests returns proper JSON format
 Test GET /api/requests with salesperson filter (Luyanda, James, Stefan)
 Test GET /api/requests with showAll parameter controls filtering
 Test showNewButton visibility based on showAll parameter
 Test POST /api/requests creates new request with generated QR-xxx ID
 Test POST /api/requests supports inline updates for existing requests
 Test DELETE /api/requests removes request successfully
 Test validation errors return 422 status with proper error details
 Verify all database queries use proper indexes (check generated columns)
 Run unit tests and verify they pass

Checkbox: - [ ] 3.1 Core Request Management API Complete

3.2 Submit & Pipedrive Integration API
Goal: Implement submission logic with mock/real mode support
Cursor Prompt:
Create submission API that handles both mock and real Pipedrive submissions with proper validation.

Create `/lib/pipedrive.ts` for Pipedrive integration:

import { log } from './log';
import { ExternalError } from './errors';

const PIPEDRIVE_API_TOKEN = process.env.PIPEDRIVE_API_TOKEN;
const PIPEDRIVE_BASE_URL = process.env.PIPEDRIVE_BASE_URL || 'https://api.pipedrive.com/v1';

export interface PipedriveDeal {
  title: string;
  pipeline_id: number;
  stage_id: number;
  person_id: number;
  org_id?: number;
  user_id: number;
}

export interface PipedriveProduct {
  product_id: number;
  quantity: number;
  item_price: number;
}

const callPipedriveAPI = async (endpoint: string, method: string = 'GET', data?: any) => {
  const url = `${PIPEDRIVE_BASE_URL}${endpoint}?api_token=${PIPEDRIVE_API_TOKEN}`;
  
  try {
    const response = await fetch(url, {
      method,
      headers: {
        'Content-Type': 'application/json',
      },
      body: data ? JSON.stringify(data) : undefined,
      signal: AbortSignal.timeout(30000), // 30 second timeout
    });
    
    if (!response.ok) {
      throw new ExternalError(`Pipedrive API error: ${response.status} ${response.statusText}`);
    }
    
    return await response.json();
  } catch (error) {
    log('Pipedrive API call failed', { endpoint, method, error });
    throw new ExternalError(`Failed to call Pipedrive API: ${error.message}`);
  }
};

export const createDeal = async (dealData: PipedriveDeal) => {
  const response = await callPipedriveAPI('/deals', 'POST', dealData);
  return response.data;
};

export const addProductsToDeal = async (dealId: number, products: PipedriveProduct[]) => {
  const promises = products.map(product => 
    callPipedriveAPI(`/deals/${dealId}/products`, 'POST', product)
  );
  
  return await Promise.all(promises);
};

export const fetchContacts = async () => {
  const [personsResponse, orgsResponse] = await Promise.all([
    callPipedriveAPI('/persons?limit=500'),
    callPipedriveAPI('/organizations?limit=500')
  ]);
  
  return {
    persons: personsResponse.data || [],
    organizations: orgsResponse.data || []
  };
};

export const fetchProducts = async () => {
  const response = await callPipedriveAPI('/products?limit=500');
  return response.data || [];
};

Create `/app/api/submit/route.ts`:

import { NextRequest } from 'next/server';
import { getDb } from '@/lib/db';
import { createDeal, addProductsToDeal } from '@/lib/pipedrive';
import { errorToResponse, ValidationError, NotFoundError } from '@/lib/errors';
import { log } from '@/lib/log';
import { z } from 'zod';

const SubmitRequest = z.object({
  id: z.string().uuid().optional(),
  requestId: z.string().optional()
});

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { id, requestId } = SubmitRequest.parse(body);
    
    if (!id && !requestId) {
      throw new ValidationError('Must provide either id or requestId');
    }
    
    const db = getDb();
    let query = db.from('requests').select('*');
    
    if (id) {
      query = query.eq('id', id);
    } else {
      query = query.eq('request_id', requestId);
    }
    
    const { data: request, error } = await query.single();
    
    if (error || !request) {
      throw new NotFoundError('Request not found');
    }
    
    // Validate request has contact and line items
    if (!request.contact) {
      throw new ValidationError('Request must have a contact before submission');
    }
    
    if (!request.line_items || request.line_items.length === 0) {
      throw new ValidationError('Request must have at least one line item before submission');
    }
    
    const submitMode = process.env.PIPEDRIVE_SUBMIT_MODE || 'real';
    
    if (submitMode === 'mock') {
      // Mock submission
      const mockDealId = Math.floor(100000 + Math.random() * 900000);
      
      const { error: mockError } = await db
        .from('mock_pipedrive_submissions')
        .insert({
          request_id: request.request_id,
          payload: {
            contact: request.contact,
            line_items: request.line_items,
            comment: request.comment
          },
          simulated_deal_id: mockDealId
        });
      
      if (mockError) {
        log('Error creating mock submission', { error: mockError });
        throw mockError;
      }
      
      // Update request status
      await db
        .from('requests')
        .update({ 
          status: 'submitted',
          pipedrive_deal_id: mockDealId 
        })
        .eq('id', request.id);
      
      log('Mock submission successful', { 
        request_id: request.request_id, 
        mock_deal_id: mockDealId 
      });
      
      return Response.json({ 
        ok: true, 
        dealId: mockDealId, 
        dealUrl: `#mock-deal-${mockDealId}`,
        mode: 'mock' 
      });
      
    } else {
      // Real Pipedrive submission
      const dealTitle = `[${request.request_id}] - [${request.contact.mineGroup || 'Unknown'}] - [${request.contact.mineName || 'Unknown'}]`;
      
      const dealData = {
        title: dealTitle,
        pipeline_id: 9, // Your pipeline ID
        stage_id: 57,   // Your stage ID
        person_id: request.contact.personId,
        org_id: request.contact.orgId,
        user_id: 123456 // Your user ID
      };
      
      const deal = await createDeal(dealData);
      
      // Add line items to deal
      const products = request.line_items.map(item => ({
        product_id: item.pipedriveProductId,
        quantity: item.quantity,
        item_price: item.price || 0
      }));
      
      await addProductsToDeal(deal.id, products);
      
      // Update request status
      await db
        .from('requests')
        .update({ 
          status: 'submitted',
          pipedrive_deal_id: deal.id 
        })
        .eq('id', request.id);
      
      log('Real submission successful', { 
        request_id: request.request_id, 
        deal_id: deal.id 
      });
      
      return Response.json({ 
        ok: true, 
        dealId: deal.id, 
        dealUrl: `https://yourcompany.pipedrive.com/deal/${deal.id}`,
        mode: 'real' 
      });
    }
    
  } catch (e) {
    if (e instanceof z.ZodError) {
      return errorToResponse(new ValidationError('Invalid submission data'));
    }
    return errorToResponse(e);
  }
}
Manual Validation Steps:

 Test mock submission creates entry in mock_pipedrive_submissions table
 Test mock submission updates request status to 'submitted'
 Test validation errors for requests without contact or line items
 Test submission fails gracefully with invalid request ID
 Verify Pipedrive API timeout handling (can mock timeout)
 Test environment variable PIPEDRIVE_SUBMIT_MODE switches behavior
 Check that real mode calls would work (test API token validity)

Checkbox: - [ ] 3.2 Submit & Pipedrive Integration API Complete

3.3 Contacts & Products API with Caching
Goal: Implement data fetching APIs with intelligent caching, offline support, and PRD-specific hierarchical structure
Cursor Prompt:
Create caching system and APIs for contacts and products with offline tolerance and PRD hierarchical structure.

Create `/lib/cache.ts` (referenced by contacts and products APIs above):

import { getDb } from './db';
import { log } from './log';

const CACHE_MAX_AGE_MS = 24 * 60 * 60 * 1000; // 24 hours

export interface CacheEntry {
  key: string;
  value: any;
  updated_at: string;
}

export class KVCache {
  private db = getDb();
  
  async get(key: string): Promise<{ data: any; stale: boolean } | null> {
    try {
      const { data, error } = await this.db
        .from('kv_cache')
        .select('*')
        .eq('key', key)
        .single();
      
      if (error || !data) {
        return null;
      }
      
      const age = Date.now() - new Date(data.updated_at).getTime();
      const stale = age > CACHE_MAX_AGE_MS;
      
      log(`Cache ${stale ? 'stale hit' : 'hit'}`, { key, age_hours: age / (1000 * 60 * 60) });
      
      return {
        data: data.value,
        stale
      };
    } catch (error) {
      log('Cache get error', { key, error });
      return null;
    }
  }
  
  async set(key: string, value: any): Promise<void> {
    try {
      const { error } = await this.db
        .from('kv_cache')
        .upsert({
          key,
          value,
          updated_at: new Date().toISOString()
        });
      
      if (error) {
        log('Cache set error', { key, error });
        throw error;
      }
      
      log('Cache set', { key });
    } catch (error) {
      log('Cache set failed', { key, error });
      throw error;
    }
  }
  
  async bust(key: string): Promise<void> {
    try {
      const { error } = await this.db
        .from('kv_cache')
        .delete()
        .eq('key', key);
      
      if (error) {
        log('Cache bust error', { key, error });
        throw error;
      }
      
      log('Cache busted', { key });
    } catch (error) {
      log('Cache bust failed', { key, error });
    }
  }
}

const cache = new KVCache();

// PRD-specific hierarchical transformation for contacts
export const transformContactsHierarchy = (persons: any[], organizations: any[]) => {
  const orgMap = new Map(organizations.map(org => [org.id, org]));
  
  const grouped = persons.reduce((acc, person) => {
    const org = orgMap.get(person.org_id?.value);
    // PRD requirement: Group by Mine Group > Mine Name > Persons
    const mineGroup = org?.['your_mine_group_field_id'] || 'Unknown Group';
    const mineName = person.org_id?.name || 'Unknown Mine';
    
    if (!acc[mineGroup]) acc[mineGroup] = {};
    if (!acc[mineGroup][mineName]) acc[mineGroup][mineName] = [];
    
    acc[mineGroup][mineName].push({
      personId: person.id,
      name: person.name,
      email: person.email?.[0]?.value || null,
      phone: person.phone?.[0]?.value || null,
      orgId: person.org_id?.value,
      orgName: person.org_id?.name,
      mineGroup,
      mineName
    });
    
    return acc;
  }, {});
  
  return grouped;
};

// PRD-specific hierarchical transformation for products
export const transformProductsHierarchy = (products: any[]) => {
  const categoryMap = {
    '1': 'Safety Equipment',
    '2': 'Mining Tools',
    '3': 'Personal Protective Equipment',
    '4': 'Machinery Parts'
  };
  
  return products.reduce((acc, product) => {
    const category = categoryMap[product.category] || 'Other';
    
    if (!acc[category]) acc[category] = [];
    
    acc[category].push({
      pipedriveProductId: product.id,
      name: product.name,
      code: product.code,
      price: product.price || 0,
      shortDescription: product.description || ''
    });
    
    return acc;
  }, {});
};

Create `/app/api/contacts/route.ts` (uses cache.ts created above):

import { NextRequest } from 'next/server';
import { KVCache, transformContactsHierarchy } from '@/lib/cache';
import { fetchContacts } from '@/lib/pipedrive';
import { errorToResponse, ExternalError } from '@/lib/errors';
import { log } from '@/lib/log';

const cache = new KVCache();
const CONTACTS_CACHE_KEY = 'contacts:hierarchical'; // PRD: hierarchical structure

export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const q = searchParams.get('q'); // Optional text filter
    
    // Try cache first
    const cached = await cache.get(CONTACTS_CACHE_KEY);
    
    if (cached && !cached.stale) {
      log('Serving fresh contacts from cache');
      return Response.json({ 
        ok: true, 
        data: cached.data, 
        stale: false,
        source: 'cache'
      });
    }
    
    try {
      // Fetch fresh data from Pipedrive
      log('Fetching fresh contacts from Pipedrive');
      const { persons, organizations } = await fetchContacts();
      
      // PRD requirement: Transform to hierarchical Mine Group > Mine Name structure
      const hierarchicalData = transformContactsHierarchy(persons, organizations);
      
      // Update cache
      await cache.set(CONTACTS_CACHE_KEY, hierarchicalData);
      
      return Response.json({ 
        ok: true, 
        data: hierarchicalData, 
        stale: false,
        source: 'pipedrive'
      });
      
    } catch (pipedriveError) {
      log('Pipedrive fetch failed, checking for stale cache', { error: pipedriveError });
      
      // Fallback to stale cache if available
      if (cached) {
        log('Serving stale contacts from cache due to Pipedrive failure');
        return Response.json({ 
          ok: true, 
          data: cached.data, 
          stale: true,
          source: 'cache_fallback',
          error: 'Pipedrive temporarily unavailable'
        });
      }
      
      // No cache available, return error
      throw new ExternalError('Unable to fetch contacts and no cached data available');
    }
    
  } catch (e) {
    return errorToResponse(e);
  }
}

Create `/app/api/products/route.ts` (uses cache.ts and pipedrive.ts created above):

import { NextRequest } from 'next/server';
import { KVCache, transformProductsHierarchy } from '@/lib/cache';
import { fetchProducts } from '@/lib/pipedrive';
import { errorToResponse, ExternalError } from '@/lib/errors';
import { log } from '@/lib/log';

const cache = new KVCache();
const PRODUCTS_CACHE_KEY = 'products:categorized'; // PRD: categorized structure

export async function GET(request: NextRequest) {
  try {
    // Try cache first
    const cached = await cache.get(PRODUCTS_CACHE_KEY);
    
    if (cached && !cached.stale) {
      log('Serving fresh products from cache');
      return Response.json({ 
        ok: true, 
        data: cached.data, 
        stale: false,
        source: 'cache'
      });
    }
    
    try {
      // Fetch fresh data from Pipedrive
      log('Fetching fresh products from Pipedrive');
      const products = await fetchProducts();
      
      // PRD requirement: Transform to categorized structure
      const categorizedData = transformProductsHierarchy(products);
      
      // Update cache
      await cache.set(PRODUCTS_CACHE_KEY, categorizedData);
      
      return Response.json({ 
        ok: true, 
        data: categorizedData, 
        stale: false,
        source: 'pipedrive'
      });
      
    } catch (pipedriveError) {
      log('Pipedrive fetch failed, checking for stale cache', { error: pipedriveError });
      
      // Fallback to stale cache if available
      if (cached) {
        log('Serving stale products from cache due to Pipedrive failure');
        return Response.json({ 
          ok: true, 
          data: cached.data, 
          stale: true,
          source: 'cache_fallback',
          error: 'Pipedrive temporarily unavailable'
        });
      }
      
      // No cache available, return error
      throw new ExternalError('Unable to fetch products and no cached data available');
    }
    
  } catch (e) {
    return errorToResponse(e);
  }
}

Create `/app/api/cache/route.ts` (uses KVCache from cache.ts above):

import { NextRequest } from 'next/server';
import { KVCache } from '@/lib/cache';
import { errorToResponse, ValidationError } from '@/lib/errors';
import { log } from '@/lib/log';
import { z } from 'zod';

const cache = new KVCache();

const BustRequest = z.object({
  keys: z.array(z.string())
});

export async function GET() {
  try {
    const db = cache['db']; // Access private db property
    const { data, error } = await db
      .from('kv_cache')
      .select('key, updated_at')
      .order('updated_at', { ascending: false });
    
    if (error) throw error;
    
    return Response.json({ 
      ok: true, 
      data: data.map(row => ({
        key: row.key,
        updated_at: row.updated_at,
        age_hours: (Date.now() - new Date(row.updated_at).getTime()) / (1000 * 60 * 60)
      }))
    });
    
  } catch (e) {
    return errorToResponse(e);
  }
}

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { keys } = BustRequest.parse(body);
    
    for (const key of keys) {
      await cache.bust(key);
    }
    
    log('Cache keys busted', { keys });
    return Response.json({ ok: true, busted: keys });
    
  } catch (e) {
    if (e instanceof z.ZodError) {
      return errorToResponse(new ValidationError('Invalid cache bust request'));
    }
    return errorToResponse(e);
  }
}
Manual Validation Steps:

 Test contacts API returns PRD hierarchical data (mineGroup > mineName > persons)
 Test products API returns categorized data
 Test cache fallback when Pipedrive is unavailable
 Test cache busting via POST /api/cache
 Verify cache age calculation and stale detection
 Test offline tolerance - app should work with stale cache
 Verify PRD data transformation functions work correctly
 Test hierarchical structure matches PRD requirements

Checkbox: - [ ] 3.3 Contacts & Products API with Caching Complete

3.4 Health Monitoring & System Status APIs
Goal: Implement comprehensive health monitoring and system diagnostics
Cursor Prompt:
Create health monitoring endpoints for production monitoring and debugging.

Create `/app/api/health/route.ts`:

export async function GET() {
  return Response.json({ 
    ok: true, 
    env: process.env.APP_ENV || 'unknown',
    timestamp: new Date().toISOString(),
    pipedrive_mode: process.env.PIPEDRIVE_SUBMIT_MODE || 'real'
  });
}

Create comprehensive health monitoring in `/app/api/health/detailed/route.ts`:

import { NextRequest } from 'next/server';
import { getDb } from '@/lib/db';
import { errorToResponse } from '@/lib/errors';

export async function GET(request: NextRequest) {
  const checks = {
    timestamp: new Date().toISOString(),
    environment: process.env.APP_ENV || 'unknown',
    version: process.env.npm_package_version || 'unknown',
    database: false,
    pipedrive_mode: process.env.PIPEDRIVE_SUBMIT_MODE || 'real'
  };
  
  try {
    // Database connectivity check
    const db = getDb();
    const { data, error } = await db
      .from('requests')
      .select('id')
      .limit(1);
    
    if (error) {
      throw new Error(`Database error: ${error.message}`);
    }
    
    checks.database = true;
    
    // Cache system check
    const { data: cacheData } = await db
      .from('kv_cache')
      .select('key')
      .limit(1);
    
    checks.cache = cacheData !== null;
    
    // Request statistics
    const { count: totalRequests } = await db
      .from('requests')
      .select('*', { count: 'exact', head: true });
    
    const { count: submittedRequests } = await db
      .from('requests')
      .select('*', { count: 'exact', head: true })
      .eq('status', 'submitted');
    
    checks.stats = {
      total_requests: totalRequests || 0,
      submitted_requests: submittedRequests || 0,
      submission_rate: totalRequests > 0 ? 
        Math.round((submittedRequests / totalRequests) * 100) : 0
    };
    
    // System status
    const allHealthy = checks.database && checks.cache !== false;
    
    return Response.json({
      ok: allHealthy,
      status: allHealthy ? 'healthy' : 'degraded',
      checks
    }, {
      status: allHealthy ? 200 : 503
    });
    
  } catch (error) {
    return errorToResponse(error);
  }
}
Manual Validation Steps:

 Test basic health endpoint returns environment info
 Test detailed health endpoint shows database connectivity
 Test detailed health endpoint shows request statistics
 Test health endpoint returns 503 when database is down
 Verify cache status is properly reported
 Test submission rate calculation accuracy

Checkbox: - [ ] 3.4 Health Monitoring & System Status APIs Complete

3.5 Production Configuration & Security
Goal: Implement production-ready configuration with security headers and optimizations
Cursor Prompt:
Create production configuration with security headers and performance optimizations.

Create production configuration `/next.config.js`:

/** @type {import('next').NextConfig} */
const nextConfig = {
  experimental: {
    serverComponentsExternalPackages: ['@supabase/supabase-js']
  },
  env: {
    NEXT_PUBLIC_APP_VERSION: process.env.npm_package_version,
    NEXT_PUBLIC_PIPEDRIVE_SUBMIT_MODE: process.env.PIPEDRIVE_SUBMIT_MODE
  },
  // Production optimizations
  compress: true,
  poweredByHeader: false,
  generateEtags: true,
  
  // Security headers
  async headers() {
    return [RetryJContinueEdit{
source: '/(.*)',
headers: [
{
key: 'X-Frame-Options',
value: 'DENY'
},
{
key: 'X-Content-Type-Options',
value: 'nosniff'
},
{
key: 'Referrer-Policy',
value: 'strict-origin-when-cross-origin'
}
]
}
];
},
// Redirects for old routes (if needed)
async redirects() {
return [
{
source: '/edit-draft',
destination: '/',
permanent: true
}
];
}
};
module.exports = nextConfig;

**Manual Validation Steps:**
- [ ] Test security headers are applied to all routes
- [ ] Test compression is enabled in production
- [ ] Test old route redirects work correctly
- [ ] Verify environment variables are properly exposed
- [ ] Test ETags are generated for static content
- [ ] Verify X-Powered-By header is removed

**Checkbox:** - [ ] 3.5 Production Configuration & Security Complete

---

## 3.6 Pre-Deployment Automation & Validation
**Goal:** Implement automated pre-deployment checks and validation

**Cursor Prompt:**
Create comprehensive pre-deployment validation system.
Create pre-deployment validation script /scripts/pre-deploy-check.js:
const { exec } = require('child_process');
const { promisify } = require('util');
const execAsync = promisify(exec);
const runPreDeployChecks = async () => {
console.log('🚀 Running pre-deployment checks...\n');
const checks = [
{
name: 'Environment Variables',
run: async () => {
require('dotenv').config();
const required = [
'SUPABASE_URL_PROD',
'SUPABASE_SERVICE_ROLE_PROD',
'PIPEDRIVE_API_TOKEN',
'PIPEDRIVE_BASE_URL'
];
    const missing = required.filter(key => !process.env[key]);
    if (missing.length > 0) {
      throw new Error(`Missing production environment variables: ${missing.join(', ')}`);
    }
    return `✅ All ${required.length} required variables present`;
  }
},
{
  name: 'Database Migration Status',
  run: async () => {
    const { stdout } = await execAsync('supabase migration list --db-url $SUPABASE_URL_PROD');
    const migrations = stdout.split('\n').filter(line => line.trim());
    const pending = migrations.filter(line => line.includes('| Pending |'));
    
    if (pending.length > 0) {
      throw new Error(`${pending.length} pending migrations found`);
    }
    return `✅ All migrations applied (${migrations.length - 1} total)`;
  }
},
{
  name: 'Unit Tests',
  run: async () => {
    const { stdout } = await execAsync('npm run test:unit');
    const passed = stdout.match(/(\d+) passed/);
    return `✅ ${passed ? passed[1] : 'All'} unit tests passed`;
  }
},
{
  name: 'Integration Tests',
  run: async () => {
    const { stdout } = await execAsync('npm run test:integration');
    const passed = stdout.match(/(\d+) passed/);
    return `✅ ${passed ? passed[1] : 'All'} integration tests passed`;
  }
},
{
  name: 'Build Process',
  run: async () => {
    await execAsync('npm run build');
    return '✅ Production build successful';
  }
},
{
  name: 'API Health Check',
  run: async () => {
    // Start server in background for health check
    const server = exec('npm start');
    await new Promise(resolve => setTimeout(resolve, 5000)); // Wait for startup
    
    try {
      const response = await fetch('http://localhost:3000/api/health');
      const data = await response.json();
      
      if (!data.ok) {
        throw new Error('Health check failed');
      }
      
      server.kill();
      return '✅ API health check passed';
    } catch (error) {
      server.kill();
      throw error;
    }
  }
},
{
  name: 'Security Scan',
  run: async () => {
    try {
      await execAsync('npm audit --audit-level high');
      return '✅ No high-severity vulnerabilities found';
    } catch (error) {
      if (error.stdout && error.stdout.includes('0 vulnerabilities')) {
        return '✅ No vulnerabilities found';
      }
      throw new Error('Security vulnerabilities detected');
    }
  }
}
];
let allPassed = true;
for (const check of checks) {
try {
console.log(⏳ ${check.name}...);
const result = await check.run();
console.log(   ${result});
} catch (error) {
console.log(   ❌ ${check.name} failed: ${error.message});
allPassed = false;
}
console.log('');
}
if (allPassed) {
console.log('🎉 All pre-deployment checks passed! Ready for production.');
process.exit(0);
} else {
console.log('💥 Some checks failed. Please fix issues before deploying.');
process.exit(1);
}
};
runPreDeployChecks().catch(error => {
console.error('Pre-deployment check failed:', error);
process.exit(1);
});

**Manual Validation Steps:**
- [ ] Test environment variable validation catches missing vars
- [ ] Test database migration status check works
- [ ] Test unit and integration test validation
- [ ] Test build process validation
- [ ] Test API health check during startup
- [ ] Test security audit catches vulnerabilities
- [ ] Verify script exits with proper codes (0 = success, 1 = failure)

**Checkbox:** - [ ] 3.6 Pre-Deployment Automation & Validation Complete

---

## 3.7 Deployment Documentation & Configuration
**Goal:** Provide comprehensive deployment guides for multiple platforms

**Cursor Prompt:**
Create complete deployment documentation and platform-specific configurations.
Create deployment documentation /docs/DEPLOYMENT.md:
Sales Helper App - Deployment Guide
Pre-Deployment Checklist
1. Environment Setup

 Production Supabase project created
 All environment variables configured in hosting platform
 Database migrations applied to production
 API tokens validated and working

2. Testing

 All unit tests passing (npm run test:unit)
 All integration tests passing (npm run test:integration)
 E2E tests passing in mock mode (npm run test:e2e)
 Manual testing of complete workflow completed

3. Security

 API tokens stored securely (not in code)
 Database access properly restricted
 Security headers configured (see next.config.js)
 No sensitive data in logs

4. Performance

 Production build optimized (npm run build)
 Database indexes created and verified
 Cache warming strategy implemented
 API response times within acceptable limits

Environment Variables
Required Production Variables
bash# App Configuration
APP_ENV=prod
NEXT_PUBLIC_APP_VERSION=1.0.0

# Database (Production Supabase)
SUPABASE_URL_PROD=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_PROD=your_service_role_key

# Pipedrive Integration
PIPEDRIVE_API_TOKEN=your_pipedrive_token
PIPEDRIVE_BASE_URL=https://api.pipedrive.com/v1
PIPEDRIVE_SUBMIT_MODE=real

# Optional: Analytics and Monitoring
NEXT_PUBLIC_ANALYTICS_ID=your_analytics_id
Deployment Options
Option 1: Vercel Deployment (Recommended)
Step 1: Connect Repository

Go to Vercel dashboard
Click "New Project"
Import your GitHub repository
Set build settings:

Build Command: npm run build
Output Directory: .next
Install Command: npm ci



Step 2: Configure Environment Variables
In Vercel dashboard → Settings → Environment Variables, add all variables from the list above.
Step 3: Deploy

Automatic deployment on git push to main branch
Or manual deploy from Vercel dashboard
Access logs via Vercel dashboard → Functions tab

Step 4: Custom Domain (Optional)

In Vercel dashboard → Settings → Domains
Add your custom domain
Update DNS records as instructed

Option 2: Docker Deployment
Step 1: Create Dockerfile
dockerfileFROM node:18-alpine AS base

# Install dependencies only when needed
FROM base AS deps
RUN apk add --no-cache libc6-compat
WORKDIR /app

# Install dependencies based on the preferred package manager
COPY package.json yarn.lock* package-lock.json* pnpm-lock.yaml* ./
RUN \
  if [ -f yarn.lock ]; then yarn --frozen-lockfile; \
  elif [ -f package-lock.json ]; then npm ci; \
  elif [ -f pnpm-lock.yaml ]; then yarn global add pnpm && pnpm i --frozen-lockfile; \
  else echo "Lockfile not found." && exit 1; \
  fi

# Rebuild the source code only when needed
FROM base AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .

RUN npm run build

# Production image, copy all the files and run next
FROM base AS runner
WORKDIR /app

ENV NODE_ENV production

RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

COPY --from=builder /app/public ./public

# Set the correct permission for prerender cache
RUN mkdir .next
RUN chown nextjs:nodejs .next

# Automatically leverage output traces to reduce image size
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs

EXPOSE 3000

ENV PORT 3000

CMD ["node", "server.js"]
Step 2: Create docker-compose.yml
yamlversion: '3.8'
services:
  sales-helper:
    build: .
    ports:
      - "3000:3000"
    env_file:
      - .env.prod
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
Step 3: Deploy
bash# Build and run
docker-compose up -d

# View logs
docker-compose logs -f sales-helper

# Update deployment
docker-compose pull && docker-compose up -d
Option 3: Traditional VPS/Server Deployment
Step 1: Server Setup
bash# Install Node.js 18+ and PM2
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs
sudo npm install -g pm2

# Clone repository
git clone https://github.com/your-repo/sales-helper-app.git
cd sales-helper-app
Step 2: Configure Environment
bash# Copy environment file
cp .env.example .env.prod
# Edit with your production values
nano .env.prod
Step 3: Build and Deploy
bash# Install dependencies and build
npm ci --only=production
npm run build

# Start with PM2
pm2 start ecosystem.config.js --env production
pm2 startup
pm2 save
Step 4: Create ecosystem.config.js
javascriptmodule.exports = {
  apps: [{
    name: 'sales-helper-app',
    script: 'npm',
    args: 'start',
    instances: 'max',
    exec_mode: 'cluster',
    env: {
      NODE_ENV: 'development'
    },
    env_production: {
      NODE_ENV: 'production',
      PORT: 3000
    },
    error_file: './logs/err.log',
    out_file: './logs/out.log',
    log_file: './logs/combined.log',
    time: true
  }]
}
Post-Deployment Verification
1. Health Checks
bash# Basic health check
curl https://your-app.com/api/health

# Detailed health check
curl https://your-app.com/api/health/detailed
2. Functionality Tests

 Create a new request through the UI
 Test contact and product loading
 Submit a request in mock mode
 Verify QR code generation and scanning
 Test cache warming and fallback

3. Performance Monitoring

 Check response times (should be < 2s)
 Monitor memory usage
 Verify cache hit rates
 Test under load (if applicable)

4. Error Monitoring

 Set up error tracking (Sentry, LogRocket, etc.)
 Configure alerting for 5xx errors
 Monitor Pipedrive API rate limits
 Set up database connection monitoring

Troubleshooting
Common Issues
1. Database Connection Errors
bash# Check environment variables
echo $SUPABASE_URL_PROD
echo $SUPABASE_SERVICE_ROLE_PROD

# Test connection manually
curl -H "Authorization: Bearer $SUPABASE_SERVICE_ROLE_PROD" \
     "$SUPABASE_URL_PROD/rest/v1/requests?limit=1"
2. Pipedrive API Issues
bash# Test API token
curl "https://api.pipedrive.com/v1/users/me?api_token=$PIPEDRIVE_API_TOKEN"

# Check rate limits
# Monitor headers: X-RateLimit-Remaining, X-RateLimit-Reset
3. Build Failures
bash# Clear Next.js cache
rm -rf .next

# Rebuild
npm run build

# Check for dependency issues
npm audit
4. Performance Issues

Enable database query logging
Check cache hit rates via /api/cache
Monitor API response times
Verify database indexes are being used

Monitoring and Maintenance
Regular Tasks

 Weekly: Check error logs and fix issues
 Monthly: Review performance metrics
 Quarterly: Update dependencies and security patches
 As needed: Scale resources based on usage

Backup Strategy

Database: Automated via Supabase
Application: Git repository with tags for releases
Environment: Secure backup of environment variables

Security Updates

Keep dependencies updated
Monitor security advisories
Regular penetration testing (for high-value deployments)
Review and rotate API tokens annually


**Manual Validation Steps:**
- [ ] Test deployment guide with fresh environment
- [ ] Verify all environment variables are documented
- [ ] Test health check endpoints work as documented
- [ ] Validate troubleshooting steps resolve common issues
- [ ] Confirm post-deployment verification checklist is complete

**Checkbox:** - [ ] 3.7 Deployment Documentation & Configuration Complete